{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCSxCm1rTLh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450de5e3-1ab4-4226-fd56-0cc7db60bc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.7/531.7 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPV8xsBqI5mj",
        "outputId": "1b7e8f44-b700-4bfd-abba-2fdb23c4d89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import os\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9IN2PtjoKXC",
        "outputId": "f8d74025-ab39-4ae5-8afe-699201c5cba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda\n",
            "Flower 1.15.2 / PyTorch 2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WpEAaN-JG5g"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def carregar_dados_no_padding(train_data, test_data, test_size=0.2, random_state=42):\n",
        "    # Load data from CSV file\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    train_data = pd.read_csv(train_data)\n",
        "    val_data = pd.read_csv(test_data)\n",
        "\n",
        "    train_data_filtered = train_data.loc[:, ~(train_data == 0).any(axis=0)]\n",
        "    val_data_filtered = val_data.loc[:, ~(val_data == 0).any(axis=0)]\n",
        "\n",
        "\n",
        "    # Split data into features (X) and targets (y) (\"hysteresis\")\n",
        "    X = train_data_filtered.drop(['hysteresis', 'joule'], axis=1)\n",
        "    y = train_data_filtered[['hysteresis', 'joule']]\n",
        "\n",
        "    # Perform train-test split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    X_test = val_data_filtered.drop(['hysteresis', 'joule'], axis=1)\n",
        "    y_test = val_data_filtered[['hysteresis', 'joule']]\n",
        "\n",
        "    X_train = scaler.fit_transform(X_train.values)\n",
        "    X_val = scaler.transform(X_val.values)\n",
        "    X_test = scaler.transform(X_test.values)\n",
        "\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfoukrnHJJq_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def plot_comparacao(y_true, y_pred):\n",
        "    # Converta para numpy se estiverem em tensores\n",
        "    if torch.is_tensor(y_true):\n",
        "        y_true = y_true.cpu().numpy()\n",
        "    if torch.is_tensor(y_pred):\n",
        "        y_pred = y_pred.cpu().numpy()\n",
        "\n",
        "    # Calcular métricas de avaliação\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Plotar a comparação\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(y_true, y_pred, color='blue', alpha=0.5, s=50, label='Previsões')\n",
        "\n",
        "    # Linha de referência (Y = X)\n",
        "    min_val = min(y_true.min(), y_pred.min())\n",
        "    max_val = max(y_true.max(), y_pred.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', linewidth=2, label='Linha de Referência')\n",
        "\n",
        "    # Adicionar título e legendas\n",
        "    plt.xlabel('Valores Reais', fontsize=12)\n",
        "    plt.ylabel('Valores Previstos', fontsize=12)\n",
        "    plt.title('Comparação entre Valores Reais e Previstos', fontsize=14)\n",
        "    plt.legend()\n",
        "\n",
        "    # Exibir métricas no gráfico\n",
        "    plt.text(min_val, max_val * 0.95, f'MAE: {mae:.4f}', fontsize=12, color='green')\n",
        "    plt.text(min_val, max_val * 0.90, f'MSE: {mse:.4f}', fontsize=12, color='green')\n",
        "    plt.text(min_val, max_val * 0.85, f'RMSE: {rmse:.4f}', fontsize=12, color='green')\n",
        "\n",
        "    # Adicionar uma grade\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Exibir o gráfico\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO7VwbzzwZCz"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, latent_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return reconstructed, latent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFzY-Yw2JKel"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, num_layers, hidden_dim):\n",
        "        super(Net, self).__init__()\n",
        "        layers = []\n",
        "\n",
        "        # Construindo as camadas com base no número de camadas\n",
        "        for i in range(num_layers):\n",
        "            layers.append(nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        # Guardar o índice da penúltima camada\n",
        "        self.penultimate_layer_index = len(layers) - 2\n",
        "\n",
        "        # Adicionar a camada final de saída\n",
        "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        # Definir a sequência de camadas como parte da rede\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        penultimate_output = None\n",
        "\n",
        "        # Executar o forward manualmente para capturar a penúltima camada\n",
        "        for i, layer in enumerate(self.network):\n",
        "            x = layer(x)\n",
        "            if i == self.penultimate_layer_index:\n",
        "                penultimate_output = x  # Armazenar a saída da penúltima camada\n",
        "\n",
        "        # Retornar a saída final e a penúltima camada\n",
        "        return x, penultimate_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MeRMPIUJWaP"
      },
      "outputs": [],
      "source": [
        "from torch import tensor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def train(model,  epochs, optimizer, trainloader, valloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "\n",
        "    # Coloca o modelo no dispositivo especificado\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Etapa de treinamento\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for inputs, targets in trainloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)  # Acumula a perda ponderada pelo batch size\n",
        "\n",
        "        train_loss /= len(trainloader.dataset)  # Média da perda por amostra\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        # Etapa de validação\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in valloader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs, _ = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        val_loss /= len(valloader.dataset)  # Média da perda por amostra\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        #print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.8f}, Val Loss: {val_loss:.8f}\")\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set for a regression problem.\"\"\"\n",
        "    criterion = torch.nn.MSELoss()  # Use MSE as the loss\n",
        "    total_loss, total_mse = 0.0, 0.0\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, targets = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
        "            outputs , _ = net(images)\n",
        "\n",
        "            # Calculate the loss (MSE)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate the MSE for accuracy\n",
        "            mse = torch.mean((outputs - targets) ** 2)\n",
        "            total_mse += mse.item()\n",
        "\n",
        "    avg_loss = total_loss / len(testloader.dataset)\n",
        "    avg_mse = total_mse / len(testloader)  # Average per batch for mse\n",
        "\n",
        "    return avg_loss, avg_mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXfKy6t6Jrgj"
      },
      "outputs": [],
      "source": [
        "def change_dataset(folder_path):\n",
        "    folder_path = folder_path\n",
        "    os.chdir(folder_path)\n",
        "\n",
        "    X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor = carregar_dados_no_padding('dados_de_treino.csv','dados_de_teste.csv')\n",
        "\n",
        "    X_train_tensor = X_train_tensor.to(device)\n",
        "    y_train_tensor = y_train_tensor.to(device)\n",
        "    X_val_tensor = X_val_tensor.to(device)\n",
        "    y_val_tensor = y_val_tensor.to(device)\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "    histeresis_train_tensor = [pair[0].item() for pair in y_train_tensor]\n",
        "    histeresis_train_tensor = torch.tensor(histeresis_train_tensor, dtype=torch.float32).to(device)\n",
        "    histeresis_train_tensor = histeresis_train_tensor.unsqueeze(1)\n",
        "\n",
        "    joule_train_tensor = [pair[1].item() for pair in y_train_tensor]\n",
        "    joule_train_tensor = torch.tensor(joule_train_tensor, dtype=torch.float32).to(device)\n",
        "    joule_train_tensor = joule_train_tensor.unsqueeze(1)\n",
        "\n",
        "    histeresis_val_tensor = [pair[0].item() for pair in y_val_tensor]\n",
        "    histeresis_val_tensor = torch.tensor(histeresis_val_tensor, dtype=torch.float32).to(device)\n",
        "    histeresis_val_tensor = histeresis_val_tensor.unsqueeze(1)\n",
        "\n",
        "    joule_val_tensor = [pair[1].item() for pair in y_val_tensor]\n",
        "    joule_val_tensor = torch.tensor(joule_val_tensor, dtype=torch.float32).to(device)\n",
        "    joule_val_tensor = joule_val_tensor.unsqueeze(1)\n",
        "\n",
        "    histeresis_test_tensor = [pair[0].item() for pair in y_test_tensor]\n",
        "    histeresis_test_tensor = torch.tensor(histeresis_test_tensor, dtype=torch.float32).to(device)\n",
        "    histeresis_test_tensor = histeresis_test_tensor.unsqueeze(1)\n",
        "\n",
        "    joule_test_tensor = [pair[1].item() for pair in y_test_tensor]\n",
        "    joule_test_tensor = torch.tensor(joule_test_tensor, dtype=torch.float32).to(device)\n",
        "    joule_test_tensor = joule_test_tensor.unsqueeze(1)\n",
        "\n",
        "    return X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor, X_test_tensor, y_test_tensor, histeresis_train_tensor, joule_train_tensor, histeresis_val_tensor, joule_val_tensor, histeresis_test_tensor, joule_test_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVsIcbKsSXB7"
      },
      "outputs": [],
      "source": [
        "X_train_tensorn, y_train_tensorn, X_val_tensorn, y_val_tensorn, X_test_tensorn, y_test_tensorn, histeresis_train_tensorn, joule_train_tensorn, histeresis_val_tensorn, joule_val_tensorn, histeresis_test_tensorn, joule_test_tensorn = change_dataset('/content/drive/MyDrive/FederatedLearning-main/Data/IPMSM_datasets/dataset_for_iron_losses_of_IPMSMs/Nabla')\n",
        "X_train_tensor2d, y_train_tensor2d, X_val_tensor2d, y_val_tensor2d, X_test_tensor2d, y_test_tensor2d, histeresis_train_tensor2d, joule_train_tensor2d, histeresis_val_tensor2d, joule_val_tensor2d, histeresis_test_tensor2d, joule_test_tensor2d = change_dataset('/content/drive/MyDrive/FederatedLearning-main/Data/IPMSM_datasets/dataset_for_iron_losses_of_IPMSMs/2D')\n",
        "X_train_tensorv, y_train_tensorv, X_val_tensorv, y_val_tensorv, X_test_tensorv, y_test_tensorv, histeresis_train_tensorv, joule_train_tensorv, histeresis_val_tensorv, joule_val_tensorv, histeresis_test_tensorv, joule_test_tensorv = change_dataset('/content/drive/MyDrive/FederatedLearning-main/Data/IPMSM_datasets/dataset_for_iron_losses_of_IPMSMs/V')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9krwU5qszi1C"
      },
      "outputs": [],
      "source": [
        "#datasets para treinamento do autoencoder\n",
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "auto_train_datasetv = TensorDataset(X_train_tensorv, X_train_tensorv)\n",
        "auto_val_datasetv = TensorDataset(X_val_tensorv, X_val_tensorv)\n",
        "auto_test_datasetv = TensorDataset(X_test_tensorv, X_test_tensorv)\n",
        "\n",
        "auto_train_datasetn = TensorDataset(X_train_tensorn, X_train_tensorn)\n",
        "auto_val_datasetn = TensorDataset(X_val_tensorn, X_val_tensorn)\n",
        "auto_test_datasetn = TensorDataset(X_test_tensorn, X_test_tensorn)\n",
        "\n",
        "auto_train_dataset2d = TensorDataset(X_train_tensor2d, X_train_tensor2d)\n",
        "auto_val_dataset2d = TensorDataset(X_val_tensor2d,X_val_tensor2d)\n",
        "auto_test_dataset2d = TensorDataset(X_test_tensor2d, X_test_tensor2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKwWInjp1YKN"
      },
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "auto_train_loader_v = DataLoader(auto_train_datasetv, batch_size=batch_size, shuffle=True)\n",
        "auto_val_loader_v = DataLoader(auto_val_datasetv, batch_size=batch_size, shuffle=False)\n",
        "auto_test_loader_v = DataLoader(auto_test_datasetv, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "auto_train_loader_n = DataLoader(auto_train_datasetn, batch_size=batch_size, shuffle=True)\n",
        "auto_val_loader_n = DataLoader(auto_val_datasetn, batch_size=batch_size, shuffle=False)\n",
        "auto_test_loader_n = DataLoader(auto_test_datasetn, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "auto_train_loader_2d = DataLoader(auto_train_dataset2d, batch_size=batch_size, shuffle=True)\n",
        "auto_val_loader_2d = DataLoader(auto_val_dataset2d, batch_size=batch_size, shuffle=False)\n",
        "auto_test_loader_2d = DataLoader(auto_test_dataset2d, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9DyySwR1fQk"
      },
      "outputs": [],
      "source": [
        "modeln = Autoencoder(X_train_tensorn.shape[1],20).to(device)\n",
        "optimizern = optim.Adam(modeln.parameters(), lr=0.001)\n",
        "\n",
        "model2d = Autoencoder(X_train_tensor2d.shape[1],20).to(device)\n",
        "optimizer2d = optim.Adam(model2d.parameters(), lr=0.001)\n",
        "\n",
        "modelv = Autoencoder(X_train_tensorv.shape[1],20).to(device)\n",
        "optimizerv = optim.Adam(modelv.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7W72nsBj2QLt"
      },
      "outputs": [],
      "source": [
        "train(modeln,100,optimizern,auto_train_loader_n,auto_val_loader_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y-1t0tbP2Pzl"
      },
      "outputs": [],
      "source": [
        "train(model2d,100,optimizer2d,auto_train_loader_2d,auto_val_loader_2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oVlgpaCQ2NvR"
      },
      "outputs": [],
      "source": [
        "train(modelv,100,optimizerv,auto_train_loader_v,auto_val_loader_v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQnGZEjF4Kd-",
        "outputId": "0075dbf6-843d-41c8-8e1c-bfa8f8cc39e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.3652657468115796e-08, 1.0589215698449775e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test(modeln,auto_test_loader_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkShY_oh4Kld",
        "outputId": "b8141741-7936-4cae-eeab-2f08d82f65e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.27937542696051e-07, 8.338243519813802e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test(model2d,auto_test_loader_2d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMqOETc04KqM",
        "outputId": "f0058077-fba4-486e-b49a-0d397944459c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.481198886521607e-07, 8.713990475945665e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "test(modelv,auto_test_loader_v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npUUzVvA6LkV",
        "outputId": "5d431639-9904-4bf9-f431-4c100122faa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape do dataset codificado: torch.Size([18436, 20])\n",
            "Shape do dataset codificado: torch.Size([19328, 20])\n",
            "Shape do dataset codificado: torch.Size([19026, 20])\n",
            "Shape do dataset codificado: torch.Size([4610, 20])\n",
            "Shape do dataset codificado: torch.Size([4832, 20])\n",
            "Shape do dataset codificado: torch.Size([4757, 20])\n",
            "Shape do dataset codificado: torch.Size([4609, 20])\n",
            "Shape do dataset codificado: torch.Size([4831, 20])\n",
            "Shape do dataset codificado: torch.Size([4756, 20])\n"
          ]
        }
      ],
      "source": [
        "modeln.eval()\n",
        "modelv.eval()\n",
        "model2d.eval()\n",
        "\n",
        "encoded_dataset_n = []\n",
        "encoded_dataset_v = []\n",
        "encoded_dataset_2d = []\n",
        "\n",
        "vencoded_dataset_n = []\n",
        "vencoded_dataset_v = []\n",
        "vencoded_dataset_2d = []\n",
        "\n",
        "tencoded_dataset_n = []\n",
        "tencoded_dataset_v = []\n",
        "tencoded_dataset_2d = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_train_tensorn:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modeln.encoder(x)\n",
        "        encoded_dataset_n.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_train_tensor2d:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = model2d.encoder(x)\n",
        "        encoded_dataset_2d.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_train_tensorv:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modelv.encoder(x)\n",
        "        encoded_dataset_v.append(latent.squeeze(0).cpu())\n",
        "\n",
        "encoded_dataset_n = torch.stack(encoded_dataset_n)\n",
        "encoded_dataset_2d = torch.stack(encoded_dataset_2d)\n",
        "encoded_dataset_v = torch.stack(encoded_dataset_v)\n",
        "\n",
        "print(f\"Shape do dataset codificado: {encoded_dataset_n.shape}\")\n",
        "print(f\"Shape do dataset codificado: {encoded_dataset_2d.shape}\")\n",
        "print(f\"Shape do dataset codificado: {encoded_dataset_v.shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_val_tensorn:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modeln.encoder(x)\n",
        "        vencoded_dataset_n.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_val_tensor2d:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = model2d.encoder(x)\n",
        "        vencoded_dataset_2d.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_val_tensorv:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modelv.encoder(x)\n",
        "        vencoded_dataset_v.append(latent.squeeze(0).cpu())\n",
        "\n",
        "vencoded_dataset_n = torch.stack(vencoded_dataset_n)\n",
        "vencoded_dataset_2d = torch.stack(vencoded_dataset_2d)\n",
        "vencoded_dataset_v = torch.stack(vencoded_dataset_v)\n",
        "\n",
        "print(f\"Shape do dataset codificado: {vencoded_dataset_n.shape}\")\n",
        "print(f\"Shape do dataset codificado: {vencoded_dataset_2d.shape}\")\n",
        "print(f\"Shape do dataset codificado: {vencoded_dataset_v.shape}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_test_tensorn:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modeln.encoder(x)\n",
        "        tencoded_dataset_n.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_test_tensor2d:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = model2d.encoder(x)\n",
        "        tencoded_dataset_2d.append(latent.squeeze(0).cpu())\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x in X_test_tensorv:\n",
        "        x = x.unsqueeze(0).to(device)\n",
        "        latent = modelv.encoder(x)\n",
        "        tencoded_dataset_v.append(latent.squeeze(0).cpu())\n",
        "\n",
        "tencoded_dataset_n = torch.stack(tencoded_dataset_n)\n",
        "tencoded_dataset_2d = torch.stack(tencoded_dataset_2d)\n",
        "tencoded_dataset_v = torch.stack(tencoded_dataset_v)\n",
        "\n",
        "print(f\"Shape do dataset codificado: {tencoded_dataset_n.shape}\")\n",
        "print(f\"Shape do dataset codificado: {tencoded_dataset_2d.shape}\")\n",
        "print(f\"Shape do dataset codificado: {tencoded_dataset_v.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTx-dFSDYg-r"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "train_datasetv = TensorDataset(encoded_dataset_v, y_train_tensorv)\n",
        "val_datasetv = TensorDataset(vencoded_dataset_v, y_val_tensorv)\n",
        "test_datasetv = TensorDataset(tencoded_dataset_v, y_test_tensorv)\n",
        "\n",
        "train_datasetn = TensorDataset(encoded_dataset_n, y_train_tensorn)\n",
        "val_datasetn = TensorDataset(vencoded_dataset_n, y_val_tensorn)\n",
        "test_datasetn = TensorDataset(tencoded_dataset_n, y_test_tensorn)\n",
        "\n",
        "\n",
        "train_dataset2d = TensorDataset(encoded_dataset_2d, joule_train_tensor2d)\n",
        "val_dataset2d = TensorDataset(vencoded_dataset_2d, joule_val_tensor2d)\n",
        "test_dataset2d = TensorDataset(tencoded_dataset_2d, joule_test_tensor2d)\n",
        "\n",
        "def split_tensor_dataset(tensor_data):\n",
        "    subset_size = len(tensor_data) // NUM_CLIENTS\n",
        "    indices = np.random.permutation(len(tensor_data))\n",
        "    subsets = []\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        start = i * subset_size\n",
        "        end = (i + 1) * subset_size if i != NUM_CLIENTS - 1 else len(tensor_data)\n",
        "        subset_indices = indices[start:end]\n",
        "        subsets.append(Subset(tensor_data, subset_indices))\n",
        "    return subsets\n",
        "\n",
        "    # Divide o dataset entre os clientes\n",
        "train_subsetsn = split_tensor_dataset(train_datasetn)\n",
        "val_subsetsn = split_tensor_dataset(val_datasetn)\n",
        "\n",
        "train_subsetsv = split_tensor_dataset(train_datasetv)\n",
        "val_subsetsv = split_tensor_dataset(val_datasetv)\n",
        "\n",
        "train_subsets2d = split_tensor_dataset(train_dataset2d)\n",
        "val_subsets2d = split_tensor_dataset(val_dataset2d)\n",
        "\n",
        "def load_datasets(partition_id: int):\n",
        "    # Converte tensores para TensorDatasets\n",
        "\n",
        "    if partition_id % 3 == 0:\n",
        "        train_subsets = train_subsetsv\n",
        "        val_subsets = val_subsetsv\n",
        "        test_dataset = test_datasetv\n",
        "    elif partition_id % 2 == 0:\n",
        "        train_subsets = train_subsetsn\n",
        "        val_subsets = val_subsetsn\n",
        "        test_dataset = test_datasetn\n",
        "    else:\n",
        "        train_subsets = train_subsets2d\n",
        "        val_subsets = val_subsets2d\n",
        "        test_dataset = test_dataset2d\n",
        "\n",
        "    # Retorna o DataLoader específico para o cliente com base no partition_id\n",
        "    train_loader = DataLoader(train_subsets[partition_id], batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_subsets[partition_id], batch_size=32, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ge5CIp6cI5a"
      },
      "outputs": [],
      "source": [
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZADnhuejZUXD"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, 100, optim.Adam(self.net.parameters()),self.trainloader,self.valloader)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1_6xfOq1S-bp"
      },
      "outputs": [],
      "source": [
        "def client_fn(context: Context) -> Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = Net(20, 2, 16, 40).to(DEVICE)\n",
        "\n",
        "    # Get data partition ID from node_config\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "\n",
        "    # Ensure the dataset loading function supports partition_id, or adjust it accordingly\n",
        "    try:\n",
        "        trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "    except TypeError:\n",
        "        print(f\"load_datasets() does not support partition_id, modifying call.\")\n",
        "        trainloader, valloader, _ = load_datasets()  # Adjust to match your actual function signature\n",
        "\n",
        "    # Create a Flower client representing the organization\n",
        "    return FlowerClient(net, trainloader, valloader).to_client()\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocS2lejxsa1X"
      },
      "outputs": [],
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "# When running on GPU, assign an entire GPU for each client\n",
        "if DEVICE.type == \"cuda\":\n",
        "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
        "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
        "    # and how to set up the `backend_config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sYkolcNsgqe"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS66sRy4blKX"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Tuple, Optional\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "def evaluate(server_round: int, parameters: flwr.common.NDArrays, config: Dict[str, float]) -> Optional[Tuple[float, Dict[str, float]]]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Criar o modelo e transferi-lo para o dispositivo\n",
        "    net = Net(20, 2, 16, 40).to(DEVICE)\n",
        "\n",
        "    # Carregar o DataLoader para os dados de teste\n",
        "    _, _, testloader = load_datasets(0)  # Ajuste conforme seu código para carregar dados\n",
        "\n",
        "    # Atualizar o modelo com os parâmetros mais recentes\n",
        "    set_parameters(net, parameters)\n",
        "    def test(net, testloader):\n",
        "        \"\"\"Evaluate the network on the entire test set for a regression problem.\"\"\"\n",
        "        mse_criterion = torch.nn.MSELoss()  # Mean Squared Error\n",
        "        mae_criterion = torch.nn.L1Loss()  # Mean Absolute Error\n",
        "        total_mse, total_mae, total_mape = 0.0, 0.0, 0.0\n",
        "        net.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images, targets = batch[0].to(DEVICE), batch[1].to(DEVICE)\n",
        "                outputs, _ = net(images)\n",
        "\n",
        "                # Calculate MSE\n",
        "                mse = mse_criterion(outputs, targets)\n",
        "                total_mse += mse.item()\n",
        "\n",
        "                # Calculate MAE\n",
        "                mae = mae_criterion(outputs, targets)\n",
        "                total_mae += mae.item()\n",
        "\n",
        "                # Calculate MAPE (avoid division by zero)\n",
        "                epsilon = 1e-8  # Small value to avoid division by zero\n",
        "                mape = torch.mean(torch.abs((outputs - targets) / (targets + epsilon))) * 100\n",
        "                total_mape += mape.item()\n",
        "\n",
        "        # Average metrics per batch\n",
        "        avg_mse = total_mse / len(testloader)\n",
        "        avg_mae = total_mae / len(testloader)\n",
        "        avg_mape = total_mape / len(testloader)\n",
        "        return avg_mse,avg_mae,avg_mape\n",
        "\n",
        "    avg_mse,avg_mae,avg_mape = test(net,testloader)\n",
        "    return avg_mse, {\"MAE\": avg_mae, \"MAPE\": avg_mape}  # Retornando MSE e um dicionário com MAE e MAPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ky9K-0siSa",
        "outputId": "f2b1ac79-7b78-4b3b-ff72-cdb3f505f520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=15, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=2279)\u001b[0m 2025-03-07 17:33:42.421290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=2279)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=2279)\u001b[0m E0000 00:00:1741368822.444369    2279 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=2279)\u001b[0m E0000 00:00:1741368822.450750    2279 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 1.0433953523635864, {'MAE': 0.8559846758842469, 'MAPE': 190.35438079833983}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([12, 1])) that is different to the input size (torch.Size([12, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m /usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[36m(ClientAppActor pid=2279)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.8582243680953979, {'MAE': 0.7705282390117645, 'MAPE': 160.80952987670898}, 311.870584548)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.48274676501750946, {'MAE': 0.552954351902008, 'MAPE': 323.9651733398438}, 621.909638708)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.5167869746685028, {'MAE': 0.5739316523075104, 'MAPE': 322.40291900634764}, 936.4028493290001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.5089080661535264, {'MAE': 0.5597760915756226, 'MAPE': 282.88174896240236}, 1246.950787748)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.49247716963291166, {'MAE': 0.5488336980342865, 'MAPE': 259.2118942260742}, 1563.7250747449998)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (6, 0.4812211275100708, {'MAE': 0.5477856040000916, 'MAPE': 259.40701217651366}, 1880.325031672)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (7, 0.4744820982217789, {'MAE': 0.5486553311347961, 'MAPE': 249.23656997680663}, 2194.9998803)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (8, 0.4679936707019806, {'MAE': 0.5438438713550567, 'MAPE': 242.5651107788086}, 2508.792040107)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (9, 0.465678995847702, {'MAE': 0.5453661143779754, 'MAPE': 243.37219314575196}, 2820.022749871)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (10, 0.46584818661212923, {'MAE': 0.5449971556663513, 'MAPE': 233.7053565979004}, 3131.298359548)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (11, 0.4531466782093048, {'MAE': 0.5410901010036469, 'MAPE': 231.74536056518554}, 3443.368280236)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (12, 0.45214212536811826, {'MAE': 0.5415863573551178, 'MAPE': 231.33081817626953}, 3757.775579765)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (13, 0.4472054898738861, {'MAE': 0.534925377368927, 'MAPE': 218.09726104736328}, 4070.325729961)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (14, 0.44146325886249543, {'MAE': 0.533785367012024, 'MAPE': 221.90827407836915}, 4385.753580062001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (15, 0.4448464274406433, {'MAE': 0.5373192250728607, 'MAPE': 220.120166015625}, 4703.206366382)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 15 round(s) in 4703.72s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.02969950033854385\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.022089293023657804\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.01765838397767739\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.017354900868149607\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.01758178357624047\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.01613889285318941\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.016643904375253354\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.01677000820540037\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.01634978295668404\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.016762832917924474\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.015778213592236405\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.015479166175155535\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.017509754442422493\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.01500253768625232\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.014738267330434478\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 1.0433953523635864\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.8582243680953979\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.48274676501750946\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.5167869746685028\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.5089080661535264\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.49247716963291166\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.4812211275100708\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.4744820982217789\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.4679936707019806\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.465678995847702\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.46584818661212923\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 11: 0.4531466782093048\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 12: 0.45214212536811826\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 13: 0.4472054898738861\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 14: 0.44146325886249543\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 15: 0.4448464274406433\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.9187508554835069),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.6756627608042258),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.5394438564395293),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.5370482135760156),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.541154181094546),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 0.4980960635395793),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 0.5122187163092589),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 0.5100236688799495),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 0.5063954730959315),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 0.5145739851853787),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (11, 0.4887504425684088),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (12, 0.4747312569192478),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (13, 0.5368878183426795),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (14, 0.4641111118620948),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (15, 0.4551792831776978)]}\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'MAE': [(0, 0.8559846758842469),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (1, 0.7705282390117645),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (2, 0.552954351902008),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (3, 0.5739316523075104),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (4, 0.5597760915756226),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (5, 0.5488336980342865),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (6, 0.5477856040000916),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (7, 0.5486553311347961),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (8, 0.5438438713550567),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (9, 0.5453661143779754),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (10, 0.5449971556663513),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (11, 0.5410901010036469),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (12, 0.5415863573551178),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (13, 0.534925377368927),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (14, 0.533785367012024),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (15, 0.5373192250728607)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'MAPE': [(0, 190.35438079833983),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (1, 160.80952987670898),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (2, 323.9651733398438),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (3, 322.40291900634764),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (4, 282.88174896240236),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (5, 259.2118942260742),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (6, 259.40701217651366),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (7, 249.23656997680663),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (8, 242.5651107788086),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (9, 243.37219314575196),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (10, 233.7053565979004),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (11, 231.74536056518554),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (12, 231.33081817626953),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (13, 218.09726104736328),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (14, 221.90827407836915),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (15, 220.120166015625)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        }
      ],
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "    You can use settings in `context.run_config` to parameterize the\n",
        "    construction of all elements (e.g the strategy or the number of rounds)\n",
        "    wrapped in the returned ServerAppComponents object.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create FedAvg strategy\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=0.5,\n",
        "        min_fit_clients=2,\n",
        "        min_evaluate_clients=2,\n",
        "        min_available_clients=2,\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        "        evaluate_fn=evaluate  # Função de avaliação no servidor\n",
        "    )\n",
        "\n",
        "    # Configure the server for 5 rounds of training\n",
        "    config = ServerConfig(num_rounds=15)\n",
        "\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create a new server instance with the updated FedAvg strategy\n",
        "server = ServerApp(server_fn=server_fn)\n",
        "\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_CLIENTS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjYZkyoPSs4z"
      },
      "source": [
        "Centralizado:\n",
        "Nabla joule model:\n",
        "\n",
        "Test MSE: 0.007116461172699928\n",
        "\n",
        "Test MAE: 0.048829417675733566\n",
        "\n",
        "Test MAPE: 31.627193093299866%\n",
        "\n",
        "federado:\n",
        "\n",
        "MSE: 0.0093, MAE: 0.0513, MAPE: 33.53%\n",
        "\n",
        "Centralizado: Nabla hysteresis model:\n",
        "\n",
        "Test MSE: 0.004404906183481216\n",
        "\n",
        "Test MAE: 0.04279777407646179\n",
        "\n",
        "Test MAPE: 90.69336652755737%\n",
        "\n",
        "federado:\n",
        "\n",
        "MSE: 0.0060, MAE: 0.0514, MAPE: 77.05%\n",
        "\n",
        "Centralizado: V hysteresis model:\n",
        "\n",
        "Test MSE: 0.0009960791794583201\n",
        "\n",
        "Test MAE: 0.021568451076745987\n",
        "\n",
        "Test MAPE: 13.8874351978302%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR6P7_PAcP3z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}